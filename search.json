[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "posts/cs/compiler/1-cfg/index.html",
    "href": "posts/cs/compiler/1-cfg/index.html",
    "title": "컴파일러 백엔드 시리즈 1부: 제어 흐름 그래프(CFG) 구축하기",
    "section": "",
    "text": "컴파일러 백엔드에서 수행하는 모든 분석과 최적화의 첫걸음은 코드를 의미 있는 단위로 나누는 것입니다. 그 가장 기본적인 단위가 바로 기본 블록(Basic Block)입니다.\n\n기본 블록(Basic Block)이란? “단일 진입점(Single Entry), 단일 진출점(Single Exit)” 원칙을 따르는 명령어의 연속된 시퀀스입니다. 1. 단일 진입점: 코드의 맨 위에서부터 실행되거나, 다른 블록에서의 점프(jump) 대상이 되는 ‘리더(leader)’ 명령어로만 진입이 가능합니다. 블록 중간으로 점프해 들어올 수 없습니다. 2. 단일 진출점: 블록의 가장 마지막 명령어를 실행하면, 다음 블록으로 제어가 넘어갑니다. 블록 중간에서 밖으로 점프해 나갈 수 없습니다.\n\nform_blocks.py의 유일한 임무는 Bril의 선형적인 명령어 리스트를 입력받아, 이 기본 블록 원칙에 따라 여러 개의 블록 리스트로 분할하는 것입니다.\n\n\n이 스크립트는 Bril 명령어 리스트(instrs)를 처음부터 끝까지 단 한 번 선형 스캔(linear scan)하면서 블록을 나눕니다. 블록을 나누는 기준은 매우 명확하며, 다음 두 가지 규칙을 따릅니다.\n\nTerminators (종결자): br (분기), jmp (무조건 점프), ret (반환) 명령어는 현재 블록의 마지막 명령어입니다. 이 명령어를 만나면 현재 블록을 닫고 다음 명령어부터 새 블록을 시작합니다.\nLabels (레이블): 레이블은 항상 새로운 블록의 시작입니다. 따라서 레이블을 만나면, (만약 그전까지의 블록에 내용이 있었다면) 그전까지의 블록을 닫고, 이 레이블부터 새로운 블록을 시작합니다.\n\n핵심 로직은 form_blocks 함수에 있으며, Python의 제너레이터(generator)로 구현되어 있어 메모리 효율적입니다.\n# Instructions that terminate a basic block.\nTERMINATORS = 'br', 'jmp', 'ret'\n\n\ndef form_blocks(instrs):\n    \"\"\"Given a list of Bril instructions, generate a sequence of\n    instruction lists representing the basic blocks in the program.\n    \"\"\"\n\n    # Start with an empty block.\n    cur_block = []\n\n    for instr in instrs:\n        if 'op' in instr:  # It's an instruction.\n            # Add the instruction to the currently-being-formed block.\n            cur_block.append(instr)\n\n            # If this is a terminator (branching instruction), it's the\n            # last instruction in the block. Finish this block and\n            # start a new one.\n            if instr['op'] in TERMINATORS:\n                yield cur_block\n                cur_block = []\n\n        else:  # It's a label.\n            # End the block here (if it contains anything).\n            if cur_block:\n                yield cur_block\n\n            # Start a new block with the label.\n            cur_block = [instr]\n\n    # Produce the final block, if any.\n    if cur_block:\n        yield cur_block\n\n\n\n\ncur_block: 현재 구성 중인 기본 블록(명령어 리스트)을 임시로 저장하는 변수입니다.\nif 'op' in instr:: Bril에서 명령어(instruction)는 op 키를 가지고, 레이블(label)은 label 키를 가집니다. 이 라인은 현재 항목이 명령어인지 확인합니다.\n\n명령어라면 cur_block에 추가합니다.\n만약 이 명령어가 TERMINATORS 중 하나라면, 이 명령어는 현재 블록의 마지막이므로 yield 키워드를 사용해 cur_block을 반환하고, cur_block을 비워 새 블록을 준비합니다.\n\nelse:: 레이블을 만난 경우입니다. 레이블은 새로운 블록의 시작입니다.\n\nif cur_block:: 만약 레이블을 만나기 직전까지 cur_block에 명령어가 있었다면 (즉, 이전 블록이 종결자 없이 끝난 경우), 해당 블록을 yield로 반환하여 먼저 종료시킵니다.\ncur_block = [instr]: 이 레이블을 첫 번째 항목으로 하는 새로운 cur_block을 시작합니다.\n\nif cur_block: (루프 종료 후): 마지막 블록이 ret 같은 종결자로 끝나지 않았을 경우, 루프가 끝난 뒤 cur_block에 남아있는 명령어가 있을 수 있습니다. 이를 마지막 블록으로 반환합니다."
  },
  {
    "objectID": "posts/cs/compiler/1-cfg/index.html#기본-블록-basic-block-생성-cfg의-기초",
    "href": "posts/cs/compiler/1-cfg/index.html#기본-블록-basic-block-생성-cfg의-기초",
    "title": "컴파일러 백엔드 시리즈 1부: 제어 흐름 그래프(CFG) 구축하기",
    "section": "",
    "text": "컴파일러 백엔드에서 수행하는 모든 분석과 최적화의 첫걸음은 코드를 의미 있는 단위로 나누는 것입니다. 그 가장 기본적인 단위가 바로 기본 블록(Basic Block)입니다.\n\n기본 블록(Basic Block)이란? “단일 진입점(Single Entry), 단일 진출점(Single Exit)” 원칙을 따르는 명령어의 연속된 시퀀스입니다. 1. 단일 진입점: 코드의 맨 위에서부터 실행되거나, 다른 블록에서의 점프(jump) 대상이 되는 ‘리더(leader)’ 명령어로만 진입이 가능합니다. 블록 중간으로 점프해 들어올 수 없습니다. 2. 단일 진출점: 블록의 가장 마지막 명령어를 실행하면, 다음 블록으로 제어가 넘어갑니다. 블록 중간에서 밖으로 점프해 나갈 수 없습니다.\n\nform_blocks.py의 유일한 임무는 Bril의 선형적인 명령어 리스트를 입력받아, 이 기본 블록 원칙에 따라 여러 개의 블록 리스트로 분할하는 것입니다.\n\n\n이 스크립트는 Bril 명령어 리스트(instrs)를 처음부터 끝까지 단 한 번 선형 스캔(linear scan)하면서 블록을 나눕니다. 블록을 나누는 기준은 매우 명확하며, 다음 두 가지 규칙을 따릅니다.\n\nTerminators (종결자): br (분기), jmp (무조건 점프), ret (반환) 명령어는 현재 블록의 마지막 명령어입니다. 이 명령어를 만나면 현재 블록을 닫고 다음 명령어부터 새 블록을 시작합니다.\nLabels (레이블): 레이블은 항상 새로운 블록의 시작입니다. 따라서 레이블을 만나면, (만약 그전까지의 블록에 내용이 있었다면) 그전까지의 블록을 닫고, 이 레이블부터 새로운 블록을 시작합니다.\n\n핵심 로직은 form_blocks 함수에 있으며, Python의 제너레이터(generator)로 구현되어 있어 메모리 효율적입니다.\n# Instructions that terminate a basic block.\nTERMINATORS = 'br', 'jmp', 'ret'\n\n\ndef form_blocks(instrs):\n    \"\"\"Given a list of Bril instructions, generate a sequence of\n    instruction lists representing the basic blocks in the program.\n    \"\"\"\n\n    # Start with an empty block.\n    cur_block = []\n\n    for instr in instrs:\n        if 'op' in instr:  # It's an instruction.\n            # Add the instruction to the currently-being-formed block.\n            cur_block.append(instr)\n\n            # If this is a terminator (branching instruction), it's the\n            # last instruction in the block. Finish this block and\n            # start a new one.\n            if instr['op'] in TERMINATORS:\n                yield cur_block\n                cur_block = []\n\n        else:  # It's a label.\n            # End the block here (if it contains anything).\n            if cur_block:\n                yield cur_block\n\n            # Start a new block with the label.\n            cur_block = [instr]\n\n    # Produce the final block, if any.\n    if cur_block:\n        yield cur_block\n\n\n\n\ncur_block: 현재 구성 중인 기본 블록(명령어 리스트)을 임시로 저장하는 변수입니다.\nif 'op' in instr:: Bril에서 명령어(instruction)는 op 키를 가지고, 레이블(label)은 label 키를 가집니다. 이 라인은 현재 항목이 명령어인지 확인합니다.\n\n명령어라면 cur_block에 추가합니다.\n만약 이 명령어가 TERMINATORS 중 하나라면, 이 명령어는 현재 블록의 마지막이므로 yield 키워드를 사용해 cur_block을 반환하고, cur_block을 비워 새 블록을 준비합니다.\n\nelse:: 레이블을 만난 경우입니다. 레이블은 새로운 블록의 시작입니다.\n\nif cur_block:: 만약 레이블을 만나기 직전까지 cur_block에 명령어가 있었다면 (즉, 이전 블록이 종결자 없이 끝난 경우), 해당 블록을 yield로 반환하여 먼저 종료시킵니다.\ncur_block = [instr]: 이 레이블을 첫 번째 항목으로 하는 새로운 cur_block을 시작합니다.\n\nif cur_block: (루프 종료 후): 마지막 블록이 ret 같은 종결자로 끝나지 않았을 경우, 루프가 끝난 뒤 cur_block에 남아있는 명령어가 있을 수 있습니다. 이를 마지막 블록으로 반환합니다."
  },
  {
    "objectID": "posts/cs/compiler/1-cfg/index.html#제어-흐름-그래프-cfg-구축",
    "href": "posts/cs/compiler/1-cfg/index.html#제어-흐름-그래프-cfg-구축",
    "title": "컴파일러 백엔드 시리즈 1부: 제어 흐름 그래프(CFG) 구축하기",
    "section": "2. 제어 흐름 그래프 (CFG) 구축",
    "text": "2. 제어 흐름 그래프 (CFG) 구축\n앞선 단계에서 우리는 선형적인 코드를 여러 개의 ‘기본 블록’ 덩어리로 분리했습니다. 하지만 이 블록들은 아직 이름도 없고 서로 어떻게 연결되어 있는지도 모르는, 말 그대로 ’명령어 리스트의 리스트’일 뿐입니다. cfg.py의 역할은 이 블록들에 고유한 이름을 부여하고, 블록 간의 제어 흐름(간선)을 명시적으로 찾아내어 ‘전임자(predecessors)’와 ‘후임자(successors)’ 목록을 가진 완전한 그래프 자료구조를 만드는 것입니다.\n\ncfg.py 핵심 로직 분석\nCFG 구축은 다음 세 가지 주요 단계를 통해 이루어집니다.\n\n1단계: 블록 맵 생성 (block_map) 가장 먼저, 각 기본 블록(노드)을 식별할 고유한 이름이 필요합니다. block_map 함수는 form_blocks에서 생성된 블록 리스트를 순회하며 OrderedDict 자료구조를 생성합니다.\n\n레이블이 있는 블록: block[0](블록의 첫 번째 항목)이 레이블이면, 해당 레이블을 블록의 이름으로 사용하고 명령어 목록에서 레이블을 제거합니다.\n익명 블록(Anonymous Block): 레이블이 없는 블록(예: jmp나 br 바로 다음의 블록)은 fresh('b', ...) 유틸리티 함수를 호출하여 b1, b2와 같이 충돌하지 않는 새 이름을 부여받습니다.\n\n\ndef block_map(blocks):\n    \"\"\"Given a sequence of basic blocks, which are lists of instructions,\n    produce a `OrderedDict` mapping names to blocks.\n    ...\n    \"\"\"\n    by_name = OrderedDict()\n\n    for block in blocks:\n        # Generate a name for the block.\n        if 'label' in block[0]:\n            # The block has a label. Remove the label but use it for the\n            # block's name.\n            name = block[0]['label']\n            block = block[1:]\n        else:\n            # Make up a new name for this anonymous block.\n            name = fresh('b', by_name)\n\n        # Add the block to the mapping.\n        by_name[name] = block\n\n    return by_name\n\n\n2단계: 암묵적 제어 흐름 명시화 (add_terminators)\nform_blocks 단계에서 생성된 블록 중 일부는 br, jmp, ret 같은 종결자(Terminator) 명령어 없이 끝날 수 있습니다. 이는 “실행이 끝나면 코딩된 순서상의 다음 블록으로 암묵적으로 넘어간다(fall-through)”는 의미입니다. 하지만 그래프 분석을 위해서는 모든 제어 흐름이 명시적(explicit)이어야 합니다.\nadd_terminators 함수는 block_map을 순회하며 종결자가 없는 모든 블록을 찾아내어 명시적인 jmp 또는 ret 명령어를 추가합니다.\n\n종결자가 없으면서 마지막 블록이 아니면: 다음 블록으로 가는 jmp를 추가합니다.\n종결자가 없으면서 마지막 블록이면: ret를 추가합니다.\n\ndef add_terminators(blocks):\n    \"\"\"Given an ordered block map, modify the blocks to add terminators\n    to all blocks (avoiding \"fall-through\" control flow transfers).\n    \"\"\"\n    for i, block in enumerate(blocks.values()):\n        # ... (Check for empty blocks removed for brevity) ...\n        if block[-1]['op'] not in TERMINATORS:\n            if i == len(blocks) - 1:\n                block.append({'op': 'ret', 'args': []})\n            else:\n                # Otherwise, jump to the next block.\n                dest = list(blocks.keys())[i + 1]\n                block.append({'op': 'jmp', 'labels': [dest]})\n\n💡 중요: 이 add_terminators 단계가 완료된 시점에서, 각 블록의 마지막 명령어는 반드시 br, jmp, ret 중 하나가 되며, 이 명령어가 해당 블록에서 나가는 모든 간선(edge) 정보를 담고 있게 됩니다.\n\n\n\n3단계: 간선 생성 (edges)\n이제 모든 블록이 이름과 명시적인 종결자를 가졌으므로, 실제 그래프(간선)를 만들 수 있습니다. edges 함수는 blocks 맵을 순회하며 각 블록의 종결자(block[-1])를 검사합니다.\n\nsuccessors 헬퍼 함수를 통해 종결자에 포함된 labels (대상 레이블) 목록을 가져옵니다.\nsuccs[name].append(succ): 현재 블록(name)의 후임자(successor) 목록에 대상 레이블(succ)을 추가합니다.\npreds[succ].append(name): 대상 레이블 블록(succ)의 전임자(predecessor) 목록에 현재 블록(name)을 추가합니다.\n\ndef successors(instr):\n    \"\"\"Get the list of jump target labels for an instruction.\n    ...\n    \"\"\"\n    if instr['op'] in ('jmp', 'br'):\n        return instr['labels']\n    elif instr['op'] == 'ret':\n        return []  # No successors to an exit block.\n    # ...\n\ndef edges(blocks):\n    \"\"\"Given a block map containing blocks complete with terminators,\n    generate two mappings: predecessors and successors. Both map block\n    names to lists of block names.\n    \"\"\"\n    preds = {name: [] for name in blocks}\n    succs = {name: [] for name in blocks}\n    for name, block in blocks.items():\n        for succ in successors(block[-1]):\n            succs[name].append(succ)\n            preds[succ].append(name)\n    return preds, succs"
  },
  {
    "objectID": "posts/cs/compiler/1-cfg/index.html#cfg-시각화-graphviz",
    "href": "posts/cs/compiler/1-cfg/index.html#cfg-시각화-graphviz",
    "title": "컴파일러 백엔드 시리즈 1부: 제어 흐름 그래프(CFG) 구축하기",
    "section": "3. CFG 시각화 (Graphviz)",
    "text": "3. CFG 시각화 (Graphviz)\nCFG는 그래프 자료구조이므로, 텍스트로만 파악하기는 매우 어렵습니다. 특히 복잡한 분기문(if/else)이나 루프(loop)가 포함된 경우, 그래프를 시각화하는 것은 필수적입니다.\ncfg_dot.py 스크립트는 cfg.py에서 만든 CFG(블록 맵)를 입력받아, Graphviz라는 그래프 시각화 도구가 읽을 수 있는 DOT 언어 스크립트를 생성합니다.\n\ncfg_dot.py 핵심 로직 분석\n이 스크립트의 cfg_dot 함수는 이전에 우리가 정의한 함수들을 순서대로 호출합니다.\n\nblocks = block_map(form_blocks(func['instrs'])): Bril 함수로부터 기본 블록을 만들고, block_map을 호출하여 이름이 부여된 블록 맵을 생성합니다.\nadd_terminators(blocks): cfg.py에서 봤던 함수를 호출하여 모든 블록이 명시적인 종결자(간선 정보)를 갖도록 보장합니다.\n정점(Vertices) 출력: blocks.items()를 순회하며 DOT 파일에 노드(정점)를 정의합니다.\n\n-v (verbose) 옵션이 켜져 있으면, 노드를 사각형(shape=box)으로 그리고 label 속성에 해당 블록의 모든 Bril 명령어를 \\l (왼쪽 정렬 줄바꿈)로 엮어 함께 출력합니다.\n\n간선(Edges) 출력: blocks.items()를 다시 순회하며 각 블록의 마지막 명령어(block[-1])에 대해 successors 함수를 호출하여 현재블록 -&gt; 후임자블록; 형태의 DOT 간선(화살표)을 출력합니다.\n\ndef cfg_dot(bril, verbose):\n    \"\"\"Generate a GraphViz \"dot\" file showing the control flow graph for\n    a Bril program.\n    ...\n    \"\"\"\n    for func in bril['functions']:\n        print('digraph {} {{'.format(func['name']))\n\n        # 1. Get named blocks\n        blocks = block_map(form_blocks(func['instrs']))\n\n        # 2. Make edges explicit\n        add_terminators(blocks)\n\n        # 3. Add the vertices (nodes)\n        for name, block in blocks.items():\n            if verbose:\n                import briltxt\n                print(r'  {} [shape=box, xlabel=\"{}\", label=\"{}\\l\"];'.format(\n                    quote_if_needed(name),\n                    name,\n                    r'\\l'.join(briltxt.instr_to_string(i) for i in block),\n                ))\n            else:\n                print('  {};'.format(name))\n\n        # 4. Add the control-flow edges (arrows)\n        for i, (name, block) in enumerate(blocks.items()):\n            succ = successors(block[-1])\n            for label in succ:\n                print('  {} -&gt; {};'.format(quote_if_needed(name), \n                                        quote_if_needed(label)))\n\n        print('}')"
  },
  {
    "objectID": "posts/cs/compiler/1-cfg/index.html#quarto에서-cfg-시각화하기",
    "href": "posts/cs/compiler/1-cfg/index.html#quarto에서-cfg-시각화하기",
    "title": "컴파일러 백엔드 시리즈 1부: 제어 흐름 그래프(CFG) 구축하기",
    "section": "Quarto에서 CFG 시각화하기",
    "text": "Quarto에서 CFG 시각화하기\ncfg_dot.py가 생성한 DOT 코드를 .qmd 파일에 내장하면, 독자에게 실제 CFG를 인터랙티브하게 보여줄 수 있습니다.\n예를 들어, 간단한 if문 Bril 코드를 이 스크립트로 처리하면 다음과 유사한 DOT 출력을 생성합니다.\n\n\n\n\n\n\n\nmy_function\n\n\n\nentry\n\nv: int = const 4\nbr cond if.then if.else\nentry\n\n\n\nif.then\n\nv: int = add v v\njmp if.end\nif.then\n\n\n\nentry-&gt;if.then\n\n\n\n\n\nif.else\n\nv: int = const 0\njmp if.end\nif.else\n\n\n\nentry-&gt;if.else\n\n\n\n\n\nif.end\n\nprint v\nret\nif.end\n\n\n\nif.then-&gt;if.end\n\n\n\n\n\nif.else-&gt;if.end"
  },
  {
    "objectID": "posts/cs/compiler/index.html",
    "href": "posts/cs/compiler/index.html",
    "title": "컴파일러 백엔드 시리즈",
    "section": "",
    "text": "컴파일러 최적화의 기반이 되는 CFG, SSA, 데이터 흐름 분석 등을 단계별로 구현합니다."
  },
  {
    "objectID": "posts/cs/compiler/index.html#컴파일러-백엔드-시리즈",
    "href": "posts/cs/compiler/index.html#컴파일러-백엔드-시리즈",
    "title": "컴파일러 백엔드 시리즈",
    "section": "",
    "text": "컴파일러 최적화의 기반이 되는 CFG, SSA, 데이터 흐름 분석 등을 단계별로 구현합니다."
  },
  {
    "objectID": "posts/cs/compiler/3-optimization/index.html",
    "href": "posts/cs/compiler/3-optimization/index.html",
    "title": "컴파일러 백엔드 시리즈 3부: SSA를 활용한 최적화와 해제",
    "section": "",
    "text": "2부에서 우리는 복잡한 과정을 거쳐 Bril 코드를 SSA (Static Single Assignment) 폼으로 변환하고 검증했습니다. 이 모든 작업을 수행한 이유는 SSA 폼이 컴파일러 최적화(Optimization)를 매우 단순하고 강력하게 만들어주기 때문입니다.\n3부에서는 SSA 폼(혹은 일반 IR)을 활용하는 두 가지 대표적인 최적화(lvn.py, tdce.py)를 살펴보고, 최적화가 끝난 코드를 다시 실행 가능한 형태로 되돌리는 from_ssa.py를 분석합니다."
  },
  {
    "objectID": "posts/cs/compiler/3-optimization/index.html#최적화-1-lvn-local-value-numbering",
    "href": "posts/cs/compiler/3-optimization/index.html#최적화-1-lvn-local-value-numbering",
    "title": "컴파일러 백엔드 시리즈 3부: SSA를 활용한 최적화와 해제",
    "section": "7. 최적화 1: LVN (Local Value Numbering)",
    "text": "7. 최적화 1: LVN (Local Value Numbering)\nlvn.py는 가장 고전적이고 효과적인 국소 최적화(Local Optimization) 기법인 Local Value Numbering(LVN)을 구현합니다. LVN은 하나의 기본 블록 내에서 작동하며, 핵심 아이디어는 간단합니다.\n\n“이전에 똑같은 연산을 똑같은 값으로 수행한 적이 있다면, 다시 계산하지 말고 이전 결과를 재사용하자.”\n\nLVN은 한 기본 블록 내에서 다음과 같은 최적화를 동시에 수행합니다.\n\n공통 부분 표현식 제거 (Common Subexpression Elimination, CSE):\n\na = b + c;\nd = b + c; \\(\\rightarrow\\) d = id a; (d는 a와 같음)\n\n상수 폴딩 (Constant Folding):\n\na = 5 + 2; \\(\\rightarrow\\) a = const 7;\n\n복사 전파 (Copy Propagation):\n\na = b;\nc = a + 1; \\(\\rightarrow\\) c = b + 1;\n\n\n\nlvn.py 핵심 로직 분석\nLVN은 기본 블록을 스캔하면서 “값(Value)”을 식별하는 여러 개의 맵(테이블)을 유지 관리합니다.\n\nvar2num: Map&lt;VarName, ValueNumber&gt;\n\n현재 시점에 각 변수가 어떤 값 번호를 갖고 있는지 추적합니다.\n\nvalue2num: Map&lt;ValueTuple, ValueNumber&gt;\n\n특정 연산(Value(op, args))이 어떤 값 번호와 매핑되는지 저장하는 ’캐시’입니다.\n\nnum2vars: Map&lt;ValueNumber, VarName&gt;\n\n특정 값 번호를 저장하고 있는 대표 변수가 무엇인지 저장합니다. (CSE용)\n\nnum2const: Map&lt;ValueNumber, Literal&gt;\n\n특정 값 번호가 상수임을 저장합니다. (상수 폴딩용)\n\n\nlvn_block의 메인 루프는 명령어를 순회하며 다음을 수행합니다.\n\n인자(Args) 번호 조회: 명령어의 인자(argvars)가 var2num 테이블을 참조하여 어떤 값 번호(argnums)를 갖는지 확인합니다.\n값(Value) 생성: val = Value(instr['op'], argnums) 튜플을 생성합니다. (예: Value('add', (1, 2)))\n캐시 조회(CSE): num = lookup(value2num, val)\n캐시 히트 (Hit) - 중복 연산 발견!\n\n이전에 계산된 값 번호(num)를 가져옵니다.\n현재 명령어를 op: 'const' (상수 폴딩) 또는 op: 'id' (CSE/복사 전파)로 덮어씁니다.\n\n캐시 미스 (Miss) - 새로운 연산!\n\n새로운 값 번호(newnum)를 생성합니다.\nvalue2num[val] = newnum: value2num 캐시에 이 새로운 Value와 newnum을 저장합니다.\n\n\n\n💡 LVN과 SSA의 관계\n이 lvn.py 구현은 국소적(Local)입니다. 즉, 기본 블록이 끝나면 모든 테이블 정보가 사라집니다.\n반면, 2부에서 수행한 SSA 변환은 그 자체로 전역적(Global)인 ‘값 번호 매기기’(Global Value Numbering, GVN)의 한 형태입니다. SSA 폼에서는 x.0, x.1 같은 변수 이름 자체가 그 값의 고유한 ‘번호’ 역할을 하기 때문입니다."
  },
  {
    "objectID": "posts/cs/compiler/3-optimization/index.html#최적화-2-tdce-trivial-dead-code-elimination",
    "href": "posts/cs/compiler/3-optimization/index.html#최적화-2-tdce-trivial-dead-code-elimination",
    "title": "컴파일러 백엔드 시리즈 3부: SSA를 활용한 최적화와 해제",
    "section": "8. 최적화 2: TDCE (Trivial Dead Code Elimination)",
    "text": "8. 최적화 2: TDCE (Trivial Dead Code Elimination)\n최적화의 또 다른 큰 축은 “불필요한 코드”를 제거하는 것입니다. 죽은 코드(Dead Code)란, 그 코드를 실행한 결과(정의된 변수)가 프로그램의 나머지 부분 어디에서도 전혀 사용되지 않는 코드를 말합니다.\ntdce.py의 “Trivial” (간단한)이라는 이름은 이 최적화가 복잡한 데이터 흐름 분석 없이, 매우 간단한 스캔만으로 죽은 코드를 찾아낸다는 의미입니다.\n이 간단한 접근 방식은 SSA 폼에서 특히 강력합니다.\n\n일반 IR: x = 1; x = 2; print(x);\n\nx = 1은 죽은 코드가 맞지만, x라는 변수 자체는 print(x)에서 ’사용’됩니다. 이 코드가 죽었는지 판별하기 까다롭습니다.\n\nSSA 폼: x.0 = 1; x.1 = 2; print(x.1);\n\nx.0이라는 변수는 단 한 번 정의됩니다.\n프로그램 전체를 스캔해서 x.0을 args로 사용하는 명령어가 단 하나도 없다면, x.0 = 1 명령어는 명백하게(Trivially) 죽은 코드입니다.\n\n\n\ntrivial_dce_pass 핵심 로직 분석\ntrivial_dce_pass 함수는 간단한 2-Pass 알고리즘으로 동작합니다.\n\n1. Pass 1: 사용된 변수 마킹 (Mark)\n먼저, 함수 전체를 한 번 스캔하여 “단 한 번이라도 args로 사용된” 변수들의 전역 집합(global set) used를 만듭니다.\n    used = set()\n    for block in blocks:\n        for instr in block:\n            # Mark all the variable arguments as used.\n            used.update(instr.get('args', []))"
  },
  {
    "objectID": "posts/cs/compiler/3-optimization/index.html#pass-2-죽은-코드-제거-sweep",
    "href": "posts/cs/compiler/3-optimization/index.html#pass-2-죽은-코드-제거-sweep",
    "title": "컴파일러 백엔드 시리즈 3부: SSA를 활용한 최적화와 해제",
    "section": "2. Pass 2: 죽은 코드 제거 (Sweep)",
    "text": "2. Pass 2: 죽은 코드 제거 (Sweep)\nused 집합이 완성되면, 함수 전체를 다시 스캔하며 각 명령어를 필터링합니다.\n\n’dest’가 없는 명령어 (예: print, br): 절대 제거하지 않습니다 (Keep).\n’dest’가 있는 명령어: if i['dest'] in used:\n\n목적지 변수가 used 집합에 있다면: 유지합니다 (Keep).\n목적지 변수가 used 집합에 없다면: 제거합니다 (Sweep).\n\n\nnew_block = [i for i in block\n                   if 'dest' not in i or i['dest'] in used]\n// 변환 전\n.pred1:\n  v.0 = const 1;\n  br cond .after .pred2;\n.pred2:\n  v.1 = const 2;\n  jmp .after;\n.after:\n  v.2 = phi v.0 v.1; // .pred1에서 오면 v.0, .pred2에서 오면 v.1\n// 변환 후 (Phi-Lowering)\n.pred1:\n  v.0 = const 1;\n  v.2 = id v.0;      // &lt;--- .after를 위해 미리 v.2에 v.0 복사\n  br cond .after .pred2;\n.pred2:\n  v.1 = const 2;\n  v.2 = id v.1;      // &lt;--- .after를 위해 미리 v.2에 v.1 복사\n  jmp .after;\n.after:\n  // phi 함수 제거됨.\n  // 이 시점에 v.2는 항상 올바른 값을 가짐.\n\nfrom_ssa.py 핵심 로직 분석\nfunc_from_ssa 함수는 이 알고리즘을 두 단계로 구현합니다.\n\n1단계: \\(\\phi\\) 함수를 찾아 전임자에 복사본 삽입\n\n모든 블록을 순회하며 op: 'phi'인 명령어를 찾습니다.\n\\(\\phi\\) 명령어를 찾으면, instr['labels'] (전임자 블록 리스트)와 instr['args'] (가져올 변수 리스트)를 순회합니다.\n각 (label, var) 쌍에 대해:\n\npred = blocks[label]: label 이름으로 전임자 블록(pred)을 찾습니다.\npred.insert(-1, ...): pred 블록의 마지막 명령어(종결자) 바로 앞(-1 위치)에 id (복사) 명령어를 삽입합니다. ( {'op': 'id', 'args': [var], 'dest': dest} )\n\n\n2단계: \\(\\phi\\) 함수 제거\n\n모든 \\(\\phi\\) 함수에 대한 복사본 삽입이 완료된 후, 다시 블록들을 순회하며 op: 'phi'인 모든 명령어를 제거(filter out)합니다.\n\n\ndef func_from_ssa(func):\n    blocks = block_map(form_blocks(func['instrs']))\n    # ... (add_entry, add_terminators) ...\n\n    # 1단계: 전임자 블록에 'id' (복사) 명령어 삽입\n    for block in blocks.values():\n        for instr in block:\n            if instr.get('op') == 'phi':\n                dest = instr['dest']\n                for i, label in enumerate(instr['labels']):\n                    var = instr['args'][i]\n                    pred = blocks[label]\n                    pred.insert(-1, { # 종결자(-1) 앞에 복사본 삽입\n                        'op': 'id',\n                        'type': instr['type'],\n                        'args': [var],\n                        'dest': dest,\n                    })\n\n        # 2단계: 현재 블록에서 모든 phi 명령어 제거\n        new_block = [i for i in block if i.get('op') != 'phi']\n        block[:] = new_block\n\n    func['instrs'] = reassemble(blocks)"
  },
  {
    "objectID": "posts/cs/index.html",
    "href": "posts/cs/index.html",
    "title": "Computer Science",
    "section": "",
    "text": "컴퓨터 과학의 다양한 주제를 탐구합니다. 관심 있는 분야를 선택하세요.\n\n\n\nCFG, SSA, 최적화 등 컴파일러 백엔드의 핵심 원리를 구현하고 분석합니다.\n\n\n\n쇼어 알고리즘 등 양자 컴퓨터의 핵심 알고리즘을 탐구합니다."
  },
  {
    "objectID": "posts/cs/index.html#computer-science",
    "href": "posts/cs/index.html#computer-science",
    "title": "Computer Science",
    "section": "",
    "text": "컴퓨터 과학의 다양한 주제를 탐구합니다. 관심 있는 분야를 선택하세요.\n\n\n\nCFG, SSA, 최적화 등 컴파일러 백엔드의 핵심 원리를 구현하고 분석합니다.\n\n\n\n쇼어 알고리즘 등 양자 컴퓨터의 핵심 알고리즘을 탐구합니다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Tech & Math Blog",
    "section": "",
    "text": "이 블로그는 컴퓨터 과학과 수학의 다양한 주제를 다룹니다.\n\n\n\n컴파일러, 양자 컴퓨팅 등 컴퓨터 과학의 다양한 주제를 탐구합니다.\n\n\n\n측도론, 위상수학 등 순수 수학의 개념들을 정리합니다."
  },
  {
    "objectID": "index.html#분야별-탐구",
    "href": "index.html#분야별-탐구",
    "title": "My Tech & Math Blog",
    "section": "",
    "text": "이 블로그는 컴퓨터 과학과 수학의 다양한 주제를 다룹니다.\n\n\n\n컴파일러, 양자 컴퓨팅 등 컴퓨터 과학의 다양한 주제를 탐구합니다.\n\n\n\n측도론, 위상수학 등 순수 수학의 개념들을 정리합니다."
  },
  {
    "objectID": "posts/cs/shor-algorithm/index.html",
    "href": "posts/cs/shor-algorithm/index.html",
    "title": "쇼어 알고리즘 (Shor’s Algorithm)",
    "section": "",
    "text": "Shor 알고리즘은 양자 알고리즘과 정수론을 결합한 것입니다. 이 알고리즘의 양자적 핵심은 “주기 찾기(Period-Finding)”입니다.\n\n\n\n우리는 \\(F: Z_N \\to \\text{COLORS}\\) (여기서 \\(N=2^n\\)이라고 가정)를 구현하는 양자 오라클(Quantum Function, QF)에 접근할 수 있습니다.\n이 함수 \\(F\\)는 “\\(L\\)-주기성”을 갖는다고 약속되어 있습니다.\n\n즉, \\(\\forall x \\in Z_N, F(x) = F(x+L) = F(x+2L) = \\dots\\)\n더 엄밀하게는( \\(L|N\\) 가정 시), \\(F(x) = F(y) \\iff L | (y-x) \\pmod{N}\\) 입니다.\n\n예시: \\(L=4\\) 라면, 함수 \\(F\\)의 출력(색상)은 [R, G, B, Y] | [R, G, B, Y] | \\dots 와 같이 \\(0, 1, 2, 3\\) 이후로 계속 반복됩니다.\n목표: \\(F\\)는 고전적인 입력뿐 아니라 입력의 양자 중첩(superposition) 상태도 처리할 수 있습니다. 우리는 이 오라클을 사용해 \\(L\\)을 효율적으로 찾는 것이 목적입니다.\n\n\n\n\n이 주기 찾기 문제(\\(L\\)-Period Finding Problem)는 다음의 3단계로 해결할 수 있습니다.\n1단계: “Load” (중첩 상태 준비)\n\n두 개의 양자 레지스터(input, output)를 준비합니다.\nInput 레지스터에 Hadamard 게이트를 적용하여 유니폼 중첩(uniform superposition) 상태를 만듭니다.\n그 다음, 양자 오라클(QF)을 적용하여 함수 \\(F\\)의 결과값을 Output 레지스터에 “로드”합니다.\n시스템의 전체 상태는 다음과 같이 됩니다:\n\\[\\frac{1}{\\sqrt{N}} \\sum_{x=0}^{N-1} |x\\rangle |0\\rangle \\xrightarrow{QF} \\frac{1}{\\sqrt{N}} \\sum_{x=0}^{N-1} |x\\rangle |F(x)\\rangle\\]\n\n2단계: “Measure” (Output 레지스터 측정)\n\n여기서, 우리는 Output 레지스터 (색상, \\(|F(x)\\rangle\\))만 먼저 측정합니다.\n함수 \\(F\\)는 \\(L\\)-주기적이므로, 각 색상(예: \\(C^*\\))은 정확히 \\(N/L\\)번 나타납니다 ( \\(L|N\\) 가정 시).\n따라서 어떤 특정 색상 \\(C^*\\)를 측정할 확률은 \\(\\frac{N/L}{N} = \\frac{1}{L}\\) 입니다.\n(중요) 측정이 일어나는 순간, 양자 상태는 붕괴(collapse)합니다. 만약 \\(C^*\\)가 측정되었다면, Input 레지스터의 상태는 \\(F(x)=C^*\\)를 만족하는 \\(x\\)값들의 균등한 중첩 상태로 붕괴합니다.\n즉, 어떤 \\(x_0\\) ( \\(F(x_0)=C^*\\) )에 대해, 붕괴된 상태는 다음과 같습니다:\n\\[|\\psi_{C^*}\\rangle = \\sqrt{\\frac{L}{N}} \\sum_{k=0}^{(N/L)-1} |x_0 + kL\\rangle\\]\n\n3단계: “Q.F.T.” (Input 레지스터 변환 및 측정)\n\n이제 우리는 주기가 \\(L\\)인 Input 레지스터의 중첩 상태를 얻었습니다.\n이 상태에 양자 푸리에 변환 (QFT, 또는 DFT)을 적용합니다.\n주기적인 상태를 QFT하면, 그 결과는 “스파이크 트레인(Spike Train)” 형태가 됩니다. 즉, 특정 값들에서만 확률이 높게 나타납니다.\n이 “스파이크”들은 주기의 역수(\\(1/L\\))와 관련된, \\(N/L\\)의 배수가 되는 지점들( \\(k \\cdot \\frac{N}{L}\\) )에서만 나타나게 됩니다.\n이 QFT가 적용된 Input 레지스터를 최종적으로 측정하면, 우리는 \\(N/L\\)의 배수인 어떤 값 \\(s\\)를 얻게 됩니다.\n이 측정값 \\(s\\)는 \\(L\\)에 대한 강력한 “단서(clue)”가 됩니다. (예: \\(s \\approx \\frac{k \\cdot N}{L}\\))\n\n\n\n\n2단계에서 우리는 랜덤한 색상 \\(C^*\\)를 측정했습니다. 이로 인해 Input 레지스터의 상태는 \\(C^*\\)에 의존하는 \\(x_0\\)만큼 무작위로 평행이동(random translation)됩니다.\n질문: 이 “무작위 평행이동”이 우리가 \\(L\\)을 찾는 것을 방해하지 않을까요?\n답변 (Pleasing Fact): 전혀 방해하지 않습니다.\n수학적 원리 (QFT Shift Theorem): 어떤 함수 \\(f(x)\\)를 \\(Y\\)만큼 평행이동시킨 함수 \\(f^Y(x) = f(x+Y)\\)가 있다고 합시다. 이 둘을 각각 QFT(\\(\\mathcal{F}\\))하면, 그 결과는 다음과 같은 관계를 갖습니다:\n\\[\\mathcal{F}(f^Y)(s) = \\mathcal{F}(f)(s) \\cdot \\omega_N^{-sY} \\quad (\\text{단, } \\omega_N = e^{2\\pi i / N})\\]\n즉, 원본(\\(x\\)) 공간에서의 평행이동(\\(+Y\\))은 푸리에(\\(s\\)) 공간에서 위상(phase)의 변화(\\(\\cdot \\omega_N^{-sY}\\))만을 유발합니다.\n우리가 최종적으로 측정하는 것은 확률, 즉 QFT 계수의 크기 제곱(magnitude squared)입니다. 위상 인자 \\(\\omega_N^{-sY}\\)의 크기는 \\(|\\omega_N^{-sY}| = 1\\) 입니다.\n\\[\n|\\mathcal{F}(f^Y)(s)|^2 = |\\mathcal{F}(f)(s) \\cdot \\omega_N^{-sY}|^2 = |\\mathcal{F}(f)(s)|^2 \\cdot |\\omega_N^{-sY}|^2 = |\\mathcal{F}(f)(s)|^2\n\\]\n결론 (The Pleasing Fact): 어떤 랜덤 색상 \\(C^*\\)를 측정하든 (즉, 스파이크 트레인이 \\(x_0\\)만큼 아무리 무작위로 평행이동되든), 우리가 Input 레지스터에서 \\(s\\)를 측정할 최종 확률 분포는 \\(x_0\\)와 관계없이 모두 동일합니다!\n\n\n\n왜 QFT가 “스파이크 트레인”을 만들까요? 3단계에서 \\(x_0=0\\) (평행이동 무시)으로 가정한 Input 상태 \\(g(x)\\)의 QFT \\(\\hat{g}(s)\\)를 계산해 봅시다.\n\nInput 상태: \\(g(x) = \\begin{cases} 1 & \\text{if } x \\in \\{0, L, 2L, \\dots\\} \\\\ 0 & \\text{else} \\end{cases}\\)\nQFT: \\(\\hat{g}(s) = \\sum_{x=0}^{N-1} g(x) \\cdot \\omega_N^{-xs} = \\sum_{j=0}^{(N/L)-1} \\omega_N^{-(jL)s}\\)\n\n경우 1: \\(s\\)가 \\(N/L\\)의 배수인 경우 ( \\(s = k \\cdot (N/L)\\) ) \\(\\omega_N^{-jLs} = \\omega_N^{-jL \\cdot k(N/L)} = \\omega_N^{-jkN} = ( \\omega_N^N )^{-jk} = 1^{-jk} = 1\\). \\(\\hat{g}(s) = \\sum_{j=0}^{(N/L)-1} 1 = N/L\\) \\(\\to\\) (보강 간섭) 모든 항이 \\(1\\)이 되어 합이 최대가 됩니다.\n경우 2: \\(s\\)가 \\(N/L\\)의 배수가 아닌 경우 이때 \\(L \\cdot s\\)는 \\(N\\)의 배수가 아니므로 \\(r = \\omega_N^{-Ls} \\neq 1\\) 입니다. 등비수열의 합은 0이 됩니다. \\(\\hat{g}(s) = \\frac{1 - (\\omega_N^{-Ls})^{N/L}}{1 - \\omega_N^{-Ls}} = \\frac{1 - (\\omega_N^{-N})^s}{1 - \\omega_N^{-Ls}} = \\frac{1 - 1^s}{1 - r} = 0\\) \\(\\to\\) (소멸 간섭) 항들이 복소평면에서 서로를 상쇄하여 합이 \\(0\\)이 됩니다.\n결론: \\(\\hat{g}(s)\\)는 \\(s\\)가 \\(N/L\\)의 배수일 때만 \\(0\\)이 아닌 값을 갖습니다. 이것이 바로 “스파이크 트레인”의 수학적 정체입니다.\n\n\n\nShor 알고리즘이 실제로 풀어야 하는 현실적인 문제입니다.\n\n\\(M = N/L\\) 은 더 이상 정수가 아닙니다.\n각 색상은 \\(\\lfloor M \\rfloor\\) (내림) 또는 \\(\\lceil M \\rceil\\) (올림) 번 나타납니다.\n이 “글리치” 때문에, QFT 결과도 완벽한 “스파이크”가 되지 않고, \\(M=N/L\\)의 배수(이제 정수도 아님)에 “가장 가까운 정수”일 확률이 높습니다.\n\n즉, \\(s \\approx \\lfloor kM \\rceil = \\lfloor k \\cdot (N/L) \\rceil\\)\n\n\n\n\n\n다행히도, “좋은” \\(s\\) (즉, \\(s \\approx \\lfloor kM \\rceil\\))를 측정할 확률은 여전히 매우 높습니다. 이 확률의 하한선(lower bound)을 계산할 수 있습니다.\n\n\\(L \\nmid N\\)일 때 QFT 합계(\\(\\hat{g}(s)\\))는 완벽한 소멸 간섭을 일으키지 못하고 “누수(leakage)”됩니다.\n하지만 “좋은” \\(s\\)의 경우, \\(|\\delta| = |s - k(N/L)| \\le 1/2\\) 로 오차가 매우 작습니다.\n이 경우 QFT 합계 항들(\\(\\omega_N^{-jL\\delta}\\))은 복소평면에서 천천히 회전하며 “대체로” 같은 방향을 가리켜, 부분적인 보강 간섭을 일으킵니다.\n(증명) 이 합계의 크기 제곱, 즉 확률은 \\(\\Pr[\\text{\"좋은\" } s] = |\\hat{g}(s)|^2 \\ge \\left(\\frac{2}{\\pi}\\right)^2 = \\frac{4}{\\pi^2}\\) 임을 보일 수 있습니다.\n결론: \\(L \\nmid N\\)인 현실적인 경우에도, 연분수 알고리즘에 사용할 수 있는 “좋은” \\(s\\)를 측정할 확률이 최소 40.5%로 매우 높다는 것이 보장됩니다."
  },
  {
    "objectID": "posts/cs/shor-algorithm/index.html#part-1-쇼어-알고리즘의-핵심---주기-찾기-period-finding-over-z_n",
    "href": "posts/cs/shor-algorithm/index.html#part-1-쇼어-알고리즘의-핵심---주기-찾기-period-finding-over-z_n",
    "title": "쇼어 알고리즘 (Shor’s Algorithm)",
    "section": "",
    "text": "Shor 알고리즘은 양자 알고리즘과 정수론을 결합한 것입니다. 이 알고리즘의 양자적 핵심은 “주기 찾기(Period-Finding)”입니다.\n\n\n\n우리는 \\(F: Z_N \\to \\text{COLORS}\\) (여기서 \\(N=2^n\\)이라고 가정)를 구현하는 양자 오라클(Quantum Function, QF)에 접근할 수 있습니다.\n이 함수 \\(F\\)는 “\\(L\\)-주기성”을 갖는다고 약속되어 있습니다.\n\n즉, \\(\\forall x \\in Z_N, F(x) = F(x+L) = F(x+2L) = \\dots\\)\n더 엄밀하게는( \\(L|N\\) 가정 시), \\(F(x) = F(y) \\iff L | (y-x) \\pmod{N}\\) 입니다.\n\n예시: \\(L=4\\) 라면, 함수 \\(F\\)의 출력(색상)은 [R, G, B, Y] | [R, G, B, Y] | \\dots 와 같이 \\(0, 1, 2, 3\\) 이후로 계속 반복됩니다.\n목표: \\(F\\)는 고전적인 입력뿐 아니라 입력의 양자 중첩(superposition) 상태도 처리할 수 있습니다. 우리는 이 오라클을 사용해 \\(L\\)을 효율적으로 찾는 것이 목적입니다.\n\n\n\n\n이 주기 찾기 문제(\\(L\\)-Period Finding Problem)는 다음의 3단계로 해결할 수 있습니다.\n1단계: “Load” (중첩 상태 준비)\n\n두 개의 양자 레지스터(input, output)를 준비합니다.\nInput 레지스터에 Hadamard 게이트를 적용하여 유니폼 중첩(uniform superposition) 상태를 만듭니다.\n그 다음, 양자 오라클(QF)을 적용하여 함수 \\(F\\)의 결과값을 Output 레지스터에 “로드”합니다.\n시스템의 전체 상태는 다음과 같이 됩니다:\n\\[\\frac{1}{\\sqrt{N}} \\sum_{x=0}^{N-1} |x\\rangle |0\\rangle \\xrightarrow{QF} \\frac{1}{\\sqrt{N}} \\sum_{x=0}^{N-1} |x\\rangle |F(x)\\rangle\\]\n\n2단계: “Measure” (Output 레지스터 측정)\n\n여기서, 우리는 Output 레지스터 (색상, \\(|F(x)\\rangle\\))만 먼저 측정합니다.\n함수 \\(F\\)는 \\(L\\)-주기적이므로, 각 색상(예: \\(C^*\\))은 정확히 \\(N/L\\)번 나타납니다 ( \\(L|N\\) 가정 시).\n따라서 어떤 특정 색상 \\(C^*\\)를 측정할 확률은 \\(\\frac{N/L}{N} = \\frac{1}{L}\\) 입니다.\n(중요) 측정이 일어나는 순간, 양자 상태는 붕괴(collapse)합니다. 만약 \\(C^*\\)가 측정되었다면, Input 레지스터의 상태는 \\(F(x)=C^*\\)를 만족하는 \\(x\\)값들의 균등한 중첩 상태로 붕괴합니다.\n즉, 어떤 \\(x_0\\) ( \\(F(x_0)=C^*\\) )에 대해, 붕괴된 상태는 다음과 같습니다:\n\\[|\\psi_{C^*}\\rangle = \\sqrt{\\frac{L}{N}} \\sum_{k=0}^{(N/L)-1} |x_0 + kL\\rangle\\]\n\n3단계: “Q.F.T.” (Input 레지스터 변환 및 측정)\n\n이제 우리는 주기가 \\(L\\)인 Input 레지스터의 중첩 상태를 얻었습니다.\n이 상태에 양자 푸리에 변환 (QFT, 또는 DFT)을 적용합니다.\n주기적인 상태를 QFT하면, 그 결과는 “스파이크 트레인(Spike Train)” 형태가 됩니다. 즉, 특정 값들에서만 확률이 높게 나타납니다.\n이 “스파이크”들은 주기의 역수(\\(1/L\\))와 관련된, \\(N/L\\)의 배수가 되는 지점들( \\(k \\cdot \\frac{N}{L}\\) )에서만 나타나게 됩니다.\n이 QFT가 적용된 Input 레지스터를 최종적으로 측정하면, 우리는 \\(N/L\\)의 배수인 어떤 값 \\(s\\)를 얻게 됩니다.\n이 측정값 \\(s\\)는 \\(L\\)에 대한 강력한 “단서(clue)”가 됩니다. (예: \\(s \\approx \\frac{k \\cdot N}{L}\\))\n\n\n\n\n2단계에서 우리는 랜덤한 색상 \\(C^*\\)를 측정했습니다. 이로 인해 Input 레지스터의 상태는 \\(C^*\\)에 의존하는 \\(x_0\\)만큼 무작위로 평행이동(random translation)됩니다.\n질문: 이 “무작위 평행이동”이 우리가 \\(L\\)을 찾는 것을 방해하지 않을까요?\n답변 (Pleasing Fact): 전혀 방해하지 않습니다.\n수학적 원리 (QFT Shift Theorem): 어떤 함수 \\(f(x)\\)를 \\(Y\\)만큼 평행이동시킨 함수 \\(f^Y(x) = f(x+Y)\\)가 있다고 합시다. 이 둘을 각각 QFT(\\(\\mathcal{F}\\))하면, 그 결과는 다음과 같은 관계를 갖습니다:\n\\[\\mathcal{F}(f^Y)(s) = \\mathcal{F}(f)(s) \\cdot \\omega_N^{-sY} \\quad (\\text{단, } \\omega_N = e^{2\\pi i / N})\\]\n즉, 원본(\\(x\\)) 공간에서의 평행이동(\\(+Y\\))은 푸리에(\\(s\\)) 공간에서 위상(phase)의 변화(\\(\\cdot \\omega_N^{-sY}\\))만을 유발합니다.\n우리가 최종적으로 측정하는 것은 확률, 즉 QFT 계수의 크기 제곱(magnitude squared)입니다. 위상 인자 \\(\\omega_N^{-sY}\\)의 크기는 \\(|\\omega_N^{-sY}| = 1\\) 입니다.\n\\[\n|\\mathcal{F}(f^Y)(s)|^2 = |\\mathcal{F}(f)(s) \\cdot \\omega_N^{-sY}|^2 = |\\mathcal{F}(f)(s)|^2 \\cdot |\\omega_N^{-sY}|^2 = |\\mathcal{F}(f)(s)|^2\n\\]\n결론 (The Pleasing Fact): 어떤 랜덤 색상 \\(C^*\\)를 측정하든 (즉, 스파이크 트레인이 \\(x_0\\)만큼 아무리 무작위로 평행이동되든), 우리가 Input 레지스터에서 \\(s\\)를 측정할 최종 확률 분포는 \\(x_0\\)와 관계없이 모두 동일합니다!\n\n\n\n왜 QFT가 “스파이크 트레인”을 만들까요? 3단계에서 \\(x_0=0\\) (평행이동 무시)으로 가정한 Input 상태 \\(g(x)\\)의 QFT \\(\\hat{g}(s)\\)를 계산해 봅시다.\n\nInput 상태: \\(g(x) = \\begin{cases} 1 & \\text{if } x \\in \\{0, L, 2L, \\dots\\} \\\\ 0 & \\text{else} \\end{cases}\\)\nQFT: \\(\\hat{g}(s) = \\sum_{x=0}^{N-1} g(x) \\cdot \\omega_N^{-xs} = \\sum_{j=0}^{(N/L)-1} \\omega_N^{-(jL)s}\\)\n\n경우 1: \\(s\\)가 \\(N/L\\)의 배수인 경우 ( \\(s = k \\cdot (N/L)\\) ) \\(\\omega_N^{-jLs} = \\omega_N^{-jL \\cdot k(N/L)} = \\omega_N^{-jkN} = ( \\omega_N^N )^{-jk} = 1^{-jk} = 1\\). \\(\\hat{g}(s) = \\sum_{j=0}^{(N/L)-1} 1 = N/L\\) \\(\\to\\) (보강 간섭) 모든 항이 \\(1\\)이 되어 합이 최대가 됩니다.\n경우 2: \\(s\\)가 \\(N/L\\)의 배수가 아닌 경우 이때 \\(L \\cdot s\\)는 \\(N\\)의 배수가 아니므로 \\(r = \\omega_N^{-Ls} \\neq 1\\) 입니다. 등비수열의 합은 0이 됩니다. \\(\\hat{g}(s) = \\frac{1 - (\\omega_N^{-Ls})^{N/L}}{1 - \\omega_N^{-Ls}} = \\frac{1 - (\\omega_N^{-N})^s}{1 - \\omega_N^{-Ls}} = \\frac{1 - 1^s}{1 - r} = 0\\) \\(\\to\\) (소멸 간섭) 항들이 복소평면에서 서로를 상쇄하여 합이 \\(0\\)이 됩니다.\n결론: \\(\\hat{g}(s)\\)는 \\(s\\)가 \\(N/L\\)의 배수일 때만 \\(0\\)이 아닌 값을 갖습니다. 이것이 바로 “스파이크 트레인”의 수학적 정체입니다.\n\n\n\nShor 알고리즘이 실제로 풀어야 하는 현실적인 문제입니다.\n\n\\(M = N/L\\) 은 더 이상 정수가 아닙니다.\n각 색상은 \\(\\lfloor M \\rfloor\\) (내림) 또는 \\(\\lceil M \\rceil\\) (올림) 번 나타납니다.\n이 “글리치” 때문에, QFT 결과도 완벽한 “스파이크”가 되지 않고, \\(M=N/L\\)의 배수(이제 정수도 아님)에 “가장 가까운 정수”일 확률이 높습니다.\n\n즉, \\(s \\approx \\lfloor kM \\rceil = \\lfloor k \\cdot (N/L) \\rceil\\)\n\n\n\n\n\n다행히도, “좋은” \\(s\\) (즉, \\(s \\approx \\lfloor kM \\rceil\\))를 측정할 확률은 여전히 매우 높습니다. 이 확률의 하한선(lower bound)을 계산할 수 있습니다.\n\n\\(L \\nmid N\\)일 때 QFT 합계(\\(\\hat{g}(s)\\))는 완벽한 소멸 간섭을 일으키지 못하고 “누수(leakage)”됩니다.\n하지만 “좋은” \\(s\\)의 경우, \\(|\\delta| = |s - k(N/L)| \\le 1/2\\) 로 오차가 매우 작습니다.\n이 경우 QFT 합계 항들(\\(\\omega_N^{-jL\\delta}\\))은 복소평면에서 천천히 회전하며 “대체로” 같은 방향을 가리켜, 부분적인 보강 간섭을 일으킵니다.\n(증명) 이 합계의 크기 제곱, 즉 확률은 \\(\\Pr[\\text{\"좋은\" } s] = |\\hat{g}(s)|^2 \\ge \\left(\\frac{2}{\\pi}\\right)^2 = \\frac{4}{\\pi^2}\\) 임을 보일 수 있습니다.\n결론: \\(L \\nmid N\\)인 현실적인 경우에도, 연분수 알고리즘에 사용할 수 있는 “좋은” \\(s\\)를 측정할 확률이 최소 40.5%로 매우 높다는 것이 보장됩니다."
  },
  {
    "objectID": "posts/cs/shor-algorithm/index.html#part-2-쇼어의-소인수분해-알고리즘-factoring-algorithm",
    "href": "posts/cs/shor-algorithm/index.html#part-2-쇼어의-소인수분해-알고리즘-factoring-algorithm",
    "title": "쇼어 알고리즘 (Shor’s Algorithm)",
    "section": "Part 2: 쇼어의 소인수분해 알고리즘 (Factoring Algorithm)",
    "text": "Part 2: 쇼어의 소인수분해 알고리즘 (Factoring Algorithm)\n이제 Part 1에서 완성한 “주기 찾기” 알고리즘을 무기로 사용하여, 고전적으로 풀기 어려운 소인수분해(Factoring) 문제를 풉니다.\n\n7. 소인수분해 문제를 “주기 찾기”로 환원(Reduction)하기\nShor의 핵심 아이디어는 1970년대에 이미 알려진 고전 정수론을 활용한 것입니다.\n\n문제: \\(m\\)비트의 큰 합성수 \\(B=pq\\)를 소인수분해하라.\n핵심 환원: 이 문제는 \\(Z_B^*\\)에서 “1의 비자명 제곱근 \\(R\\)”을 찾는 것과 같습니다.\n\n비자명 제곱근(Non-trivial Square Root): \\(R^2 \\equiv 1 \\pmod{B}\\) 이지만, \\(R \\not\\equiv \\pm 1 \\pmod{B}\\) 인 \\(R\\).\n\n“열쇠” \\(R\\)이 “자물쇠” \\(B\\)를 여는 방법 (The GCD Trick):\n\n만약 \\(R\\)을 찾는다면, \\(R^2 - 1 \\equiv 0 \\pmod{B}\\) \\(\\implies\\) \\((R-1)(R+1) \\equiv 0 \\pmod{pq}\\) 입니다.\n\\(R\\)이 비자명하므로, \\(p\\)와 \\(q\\)는 두 인수 \\((R-1)\\)과 \\((R+1)\\)에 나누어 들어가야만 합니다. (예: \\(p | (R-1)\\) 이고 \\(q | (R+1)\\))\n[Aha!] 이 상태에서 \\(\\gcd(R-1, B) = \\gcd(R-1, pq)\\) 를 고전적으로 계산하면, 공통 인수 \\(p\\)가 즉시 나옵니다.\n\n\n\n\n8. “열쇠” \\(R\\)을 “주기” \\(L\\)로 찾기\n이제 문제는 “어떻게 \\(R\\)을 찾는가?”로 좁혀졌습니다.\n\n[Random Sampling] \\(B\\)와 서로소인 임의의 수 \\(A\\)를 고릅니다 ( \\(1 &lt; A &lt; B\\) ).\n[The Function] \\(A\\)를 밑(base)으로 하는 다음 함수 \\(F_A(x)\\)를 정의합니다: \\[F_A(x) = A^x \\pmod{B}\\]\n[The Period “L”] 이 함수는 주기적입니다. 이 함수의 주기 \\(L\\)은 \\(A^L \\equiv 1 \\pmod{B}\\) 를 만족하는 가장 작은 양의 정수 \\(L\\) ( \\(A\\)의 “차수(order)”)입니다.\n[The Final Link] Part 1의 양자 알고리즘으로 이 주기 \\(L\\)을 찾았다고 합시다.\n\n만약 \\(L\\)이 짝수라면 (랜덤 \\(A\\)에 대해 그럴 확률이 높음), \\(A^L \\equiv 1 \\pmod{B}\\) 는 \\((A^{L/2})^2 \\equiv 1 \\pmod{B}\\) 로 쓸 수 있습니다.\n“열쇠” \\(R\\)을 찾았습니다! \\(\\implies R = A^{L/2}\\)\n이 \\(R\\)은 \\(L\\)이 최소 주기이므로 \\(R \\not\\equiv 1 \\pmod{B}\\) 임이 보장됩니다.\n\\(R \\not\\equiv -1 \\pmod{B}\\) 일 확률(즉, 비자명할 확률)도 50% 이상임이 알려져 있습니다 (아래 10번 참조).\n\n\n최종 환원: 소인수분해(\\(B\\)) \\(\\to\\) 비자명 제곱근(\\(R\\)) 찾기 \\(\\to\\) \\(A^x \\pmod{B}\\)의 주기(\\(L\\)) 찾기 \\(\\to\\) Part 1의 양자 주기 찾기 알고리즘 사용!\n\n\n9. 양자적 병목 현상 및 \\(n \\ge 2m+1\\) 조건\n\n[병목] 우리가 양자 컴퓨터로 구현할 \\(F_A(x) = A^x \\pmod{B}\\) (모듈러 지수 연산)은 “제곱-곱셈” 알고리즘을 사용하며, 약 \\(O(m^3)\\) (\\(m = \\log B\\)) 개의 게이트를 필요로 합니다. 이것이 Shor 알고리즘의 양자적 병목 현상입니다.\n[정밀도] \\(L\\)을 찾는 주기 찾기 알고리즘(Part 1)이 \\(\\frac{s}{N} \\approx \\frac{k}{L}\\) 라는 근사값을 고전적인 “연분수 알고리즘”으로 풀 수 있으려면, Input 레지스터의 크기 \\(n\\) (\\(N=2^n\\))이 \\(L\\)에 비해 압도적으로 커야 합니다.\n[조건 증명] \\(L\\)은 \\(B \\approx 2^m\\) 보다 작습니다. 정수론에 따르면, 분모가 \\(B\\)보다 작은 두 다른 분수 \\(k/L\\), \\(k'/L'\\)의 차이는 \\(|\\frac{k}{L} - \\frac{k'}{L'}| &gt; \\frac{1}{B^2} \\approx \\frac{1}{2^{2m}}\\) 입니다. 우리의 알고리즘 오차 \\(\\epsilon = |\\frac{S}{N} - \\frac{k}{L}| \\le \\frac{1}{2N} = \\frac{1}{2^{n+1}}\\) 입니다. 연분수 알고리즘이 “가짜 답”과 “진짜 답”을 구별하려면, 오차(\\(\\epsilon\\))가 두 답 사이의 최소 거리(\\(1/B^2\\))보다 작아야 합니다. \\(\\frac{1}{2^{n+1}} &lt; \\frac{1}{2^{2m}} \\implies n+1 &gt; 2m \\implies n \\ge 2m+1\\) \\(\\to\\) \\(m\\)비트 숫자를 소인수분해하려면 최소 \\(n=2m+1\\) 비트의 Input 레지스터가 필요합니다.\n\n\n\n10. 고전적 “운(Luck)”과 성공 확률 (최소 50%)\n양자 컴퓨터가 주기 \\(L\\)을 성공적으로 찾아냈다고 해도, 이 \\(L\\)이 “쓸모없는” 값일 수 있습니다.\n\n실패 1: \\(L\\)이 홀수일 때 ( \\(A^{L/2}\\) 계산 불가)\n실패 2: \\(R = A^{L/2} \\equiv -1 \\pmod{B}\\) 일 때 ( \\(\\gcd(R-1, B)\\)가 \\(B\\)가 되어 실패)\n\n다행히도, 이 두 가지 실패를 모두 피할 확률은 최소 50%입니다.\n\n[증명 (CRT)] 중국인의 나머지 정리(CRT)에 따르면, \\(Z_B^* \\cong Z_p^* \\times Z_q^*\\) 입니다.\n\\(L = \\text{lcm}(L_p, L_q)\\)가 홀수일 경우는 \\(L_p, L_q\\)가 모두 홀수일 때뿐입니다. \\(Z_p^*\\) (짝수 크기의 순환군)에서 \\(L_p\\)가 홀수일 확률은 1/2입니다.\n\\(\\Pr[L\\text{ is odd}] = \\Pr[L_p\\text{ odd}] \\times \\Pr[L_q\\text{ odd}] = (1/2) \\times (1/2) = 1/4\\).\n\\(\\Pr[L\\text{ is even (1차 성공)}] = 1 - 1/4 = 3/4\\).\n\\(L\\)이 짝수일 때 2차 실패(\\(R \\equiv -1\\))가 일어날 확률은 최대 1/2입니다.\n\\(\\Pr[\\text{최종 성공}] = \\Pr[\\text{성공 1}] \\times \\Pr[\\text{성공 2} \\mid \\text{성공 1}] \\ge (3/4) \\times (1/2) = 3/8\\). (더 엄밀한 분석은 \\(\\ge 1/2\\)을 보입니다.)\n결론: 몇 번만 반복하면 “좋은 \\(A\\)”를 뽑을 수 있습니다.\n\n\n\n11. 최종 고전 후처리: 연분수 알고리즘 (Continued Fractions)\nShor 알고리즘의 마지막 단계는 순수하게 고전적입니다.\n\n상황: 우리는 \\(S\\)와 \\(N=2^n\\)을 압니다.\n가정: \\(S\\)가 \\(\\ge 40.5\\%\\) 확률로 “좋은 단서”(\\(|\\frac{S}{N} - \\frac{k}{L}| \\le \\frac{1}{2N}\\))라고 일단 가정합니다.\n알고리즘: \\(\\frac{S}{N}\\) (소수)를 연분수 알고리즘에 입력합니다.\n작동 원리: 이 알고리즘은 유클리드 호제법(GCD)을 사용하여 \\(\\frac{S}{N}\\)를 가장 잘 근사하는 “최적의 분수” \\(\\frac{k'}{L'}\\)를 효율적으로 찾습니다.\n\n(예) \\(\\gcd(N, S)\\) 계산 시: \\(N = q_1 S + r_1 \\implies S = q_2 r_1 + r_2 \\dots\\)\n이 몫(\\(q_i\\))들이 연분수 전개의 계수가 되며, \\(n \\ge 2m+1\\) 조건 덕분에 오차가 누적되어도 \\(\\frac{k'}{L'}\\)는 \\(\\frac{k}{L}\\)와 정확히 일치함이 보장됩니다.\n\n검증 (Verify):\n\n찾아낸 \\(L'\\)를 이용해 \\(A^{L'} \\equiv 1 \\pmod{B}\\) 인지 고전적으로 검증합니다.\n만약 \\(1\\)이 아니면, \\(S\\)가 “Junk”였다는 뜻이므로, 알고리즘을 다른 \\(A\\) (또는 새 \\(S\\))로 다시 시작합니다.\n\\(1\\)이 맞다면, \\(L'\\)는 유효한 주기입니다. 10단계의 “운”을 테스트(홀수/짝수, \\(-1\\) 여부)합니다.\n통과 시, \\(p = \\gcd(A^{L'/2}-1, B)\\) 를 계산하여 소인수를 찾습니다."
  },
  {
    "objectID": "posts/cs/compiler/4-toolkit/index.html",
    "href": "posts/cs/compiler/4-toolkit/index.html",
    "title": "컴파일러 백엔드 시리즈 4부(부록): 컴파일러 툴킷",
    "section": "",
    "text": "1부에서 3부까지 우리는 CFG 생성, SSA 변환, 최적화, 그리고 SSA 해제로 이어지는 컴파일러 백엔드의 핵심 파이프라인을 구축했습니다.\n이번 4부(부록)에서는 이 파이프라인을 직접 구성하지는 않지만, 그 기반이 되는 핵심 이론 프레임워크와 프로젝트를 보조하는 유용한 툴킷 파일들을 살펴봅니다."
  },
  {
    "objectID": "posts/cs/compiler/4-toolkit/index.html#심화-학습-일반적인-데이터-흐름-분석dataflow-analysis-프레임워크",
    "href": "posts/cs/compiler/4-toolkit/index.html#심화-학습-일반적인-데이터-흐름-분석dataflow-analysis-프레임워크",
    "title": "컴파일러 백엔드 시리즈 4부(부록): 컴파일러 툴킷",
    "section": "10. 심화 학습: 일반적인 데이터 흐름 분석(Dataflow Analysis) 프레임워크",
    "text": "10. 심화 학습: 일반적인 데이터 흐름 분석(Dataflow Analysis) 프레임워크\n2부의 dom.py에서 지배자(Dominator)를 계산하기 위해 ‘반복적 데이터 흐름 분석’ 알고리즘을 사용했던 것을 기억하시나요? dom.py가 ’지배자 분석’이라는 특정한(specific) 목적을 위해 하드코딩된 구현체였다면, df.py는 한발 더 나아가 어떤 종류의 데이터 흐름 분석이든 수행할 수 있도록 일반화시킨 강력한 프레임워크입니다.\n\n데이터 흐름 분석이란? CFG를 따라 프로그램의 상태 값(예: “이 변수가 상수인가?”, “이 변수가 나중에 사용되는가?”)이 어떻게 전파되는지 계산하는 정적 분석 기법입니다. 이 분석은 “고정점(fixed-point)”에 도달할 때까지, 즉 더 이상 정보가 갱신되지 않을 때까지 반복적으로 수행됩니다.\n\ndf.py는 특정 분석에 종속되지 않고, Analysis라는 명세만 넘겨주면 알아서 고정점을 찾아주는 범용 워크리스트 알고리즘(Worklist Algorithm)을 제공합니다.\n\n1. ‘Analysis’ 추상화\n이 프레임워크의 핵심은 Analysis 네임드튜플(namedtuple)입니다. 어떤 데이터 흐름 분석이든 다음 네 가지 요소로 정의할 수 있다는 아이디어에 기반합니다.\nAnalysis = namedtuple('Analysis', ['forward', 'init', 'merge', 'transfer'])\n\nforward (방향): True이면 순방향(Forward) 분석 (진입 \\(\\rightarrow\\) 종료), False이면 역방향(Backward) 분석 (종료 \\(\\rightarrow\\) 진입)을 수행합니다.\ninit (초기값): 각 블록의 in 또는 out 상태가 처음 시작할 때 가지는 값입니다. (Lattice의 \\(\\top\\) 또는 \\(\\bot\\) 원소)\nmerge (병합 함수): 여러 경로가 합쳐지는 지점(예: if문 다음 블록)에서 각 경로의 상태 값을 어떻게 합칠 것인지 정의합니다. (Meet 연산자 \\(\\cap\\) 또는 \\(\\cup\\))\ntransfer (전달 함수): 특정 블록을 통과할 때, 블록의 in 상태가 어떻게 out 상태로 변환되는지 정의합니다. ( \\(f(x)\\) )\n\n\n\n2. df_worklist 알고리즘\n이 함수가 바로 데이터 흐름 분석 엔진입니다. 모든 블록을 무작정 반복하는 대신, 상태 값에 변경이 생긴 블록의 후임자(또는 전임자)만을 worklist라는 큐에 넣어 효율적으로 고정점을 찾습니다.\ndef df_worklist(blocks, analysis):\n    # ... ( preds, succs 계산, 방향 설정 ) ...\n    \n    # 1. 초기화\n    in_ = {first_block: analysis.init}\n    out = {node: analysis.init for node in blocks}\n    \n    worklist = list(blocks.keys())\n    while worklist:\n        node = worklist.pop(0)\n\n        # 2. Merge: 모든 전임자(predecessor)들의 out 값을 병합\n        inval = analysis.merge(out[n] for n in in_edges[node])\n        in_[node] = inval\n\n        # 3. Transfer: 블록을 통과시키며 out 값을 계산\n        outval = analysis.transfer(blocks[node], inval)\n\n        # 4. 고정점 확인: out 값이 변경되었는지 확인\n        if outval != out[node]:\n            out[node] = outval\n            # 변경되었다면, 이 노드의 후임자(successor)들을 worklist에 추가\n            worklist += out_edges[node]\n            \n    # ... (결과 반환) ...\ndef normalize():\n    # ... (CSV 읽기) ...\n\n    # 1. Get normalization baselines.\n    baselines = {\n        row['benchmark']: int(row['result'])\n        for row in in_data\n        if row['run'] == 'baseline'\n    }\n\n    # 2. Write output CSV back out.\n    # ... (writer 생성) ...\n    ratios = defaultdict(list)\n    for row in in_data:\n        # 3. Calculate ratio against baseline\n        ratio = int(row['result']) / baselines[row['benchmark']]\n        ratios[row['run']].append(ratio)\n        row['result'] = ratio\n        writer.writerow(row)\n\n    # 4. Print stats.\n    for run, rs in ratios.items():\n        for name, func in STATS.items():\n            print(\n                '{}({}) = {:.2f}'.format(name, run, func(rs)),\n                file=sys.stderr,\n            )\n\n\n3. 구현된 분석 예제\ndf.py는 이 프레임워크를 사용한 두 가지 고전적인 분석을 예제로 제공합니다.\n\n1. ‘live’: 활성 변수 분석 (Live Variable Analysis)\n\n목적: 어떤 변수가 “활성(live)” 상태인지, 즉 “현재 지점에서 정의된 값이 미래에 사용될 가능성이 있는지”를 파악합니다. (주로 레지스터 할당, 정교한 죽은 코드 제거에 사용됩니다.)\n특징: 역방향(Backward) 분석입니다 (forward: False). 프로그램의 끝에서부터 거꾸로 분석을 수행합니다.\n전달 함수: \\(LiveIn(n) = Use(n) \\cup (LiveOut(n) - Gen(n))\\)\n\n\\(Use(n)\\): 이 블록에서 (정의되기 전에) 사용되는 변수.\n\\(Gen(n)\\): 이 블록에서 정의되는(덮어쓰이는) 변수.\n\n\n\n\n2. ‘cprop’: 상수 전파 (Constant Propagation)\n\n목적: “어떤 변수가 항상 특정 상수 값을 가지는가?”를 파악합니다.\n특징: 순방향(Forward) 분석입니다 (forward: True).\n상태 값: { 'v': 5, 'x': '?', 'z': 10 }\n\n5: 이 지점에서 v는 항상 5입니다.\n'?': 이 지점에서 x는 상수가 아니거나, 여러 경로에서 온 상수 값이 다릅니다 (Lattice의 \\(\\top\\)).\n\nMerge 함수 (cprop_merge):\n\nmerge({v: 5}, {v: 5}) \\(\\rightarrow\\) {v: 5}\nmerge({v: 5}, {v: 7}) \\(\\rightarrow\\) {v: '?'}"
  },
  {
    "objectID": "posts/cs/compiler/4-toolkit/index.html#최적화-성능-측정-normalize.py",
    "href": "posts/cs/compiler/4-toolkit/index.html#최적화-성능-측정-normalize.py",
    "title": "컴파일러 백엔드 시리즈 4부(부록): 컴파일러 툴킷",
    "section": "11. 최적화 성능 측정 (normalize.py)",
    "text": "11. 최적화 성능 측정 (normalize.py)\n3부에서 lvn.py (중복 연산 제거)와 tdce.py (죽은 코드 제거) 같은 최적화 패스를 구현했습니다. 그렇다면 이 최적화들이 과연 “얼마나” 코드를 향상시켰을까요?\n이를 확인하려면 벤치마킹(Benchmarking)이 필요합니다. normalize.py는 이 벤치마킹 결과를 처리해주는 유틸리티입니다.\n\nnormalize.py는 각 벤치마크의 여러 실행 결과(예: 총 명령어 수)가 담긴 CSV 파일을 입력받습니다.\n\n\nnormalize.py 핵심 로직 분석\n이 스크립트의 목적은 “절대적인 명령어 수” (예: 150개)를 “상대적인 성능 비율” (예: 0.85배)로 변환하는 것입니다.\n\nCSV 읽기: 벤치마킹 결과 CSV를 읽습니다. (예상 형식: benchmark, run, result)\n‘baseline’ 찾기: run == 'baseline'인 행을 찾아, 각 벤치마크의 기준 성능(baselines[...] = int(row['result']))을 맵에 저장합니다.\n정규화(Normalize):\n\nCSV를 다시 순회하며 각 행(row)의 result를 baseline의 result로 나눕니다.\nratio = int(row['result']) / baselines[row['benchmark']]\n(예: lvn_run의 result가 85, baseline이 100이었다면 ratio = 0.85)\n\n통계 출력:\n\n각 run (예: lvn_only)별로 모든 ratio의 기하 평균(geometric_mean)을 계산하여 출력합니다.\n\n\ndef normalize():\n    # ... (CSV 읽기) ...\n\n    # 1. Get normalization baselines.\n    baselines = {\n        row['benchmark']: int(row['result'])\n        for row in in_data\n        if row['run'] == 'baseline'\n    }\n\n    # 2. Write output CSV back out.\n    # ... (writer 생성) ...\n    ratios = defaultdict(list)\n    for row in in_data:\n        # 3. Calculate ratio against baseline\n        ratio = int(row['result']) / baselines[row['benchmark']]\n        ratios[row['run']].append(ratio)\n        row['result'] = ratio\n        writer.writerow(row)\n\n    # 4. Print stats.\n    for run, rs in ratios.items():\n        for name, func in STATS.items():\n            print(\n                '{}({}) = {:.2f}'.format(name, run, func(rs)),\n                file=sys.stderr,\n            )\n\n이 스크립트를 통해 “LVN 최적화를 켰더니, 기준(baseline) 대비 명령어 수가 평균 85% 수준(기하 평균 0.85)이 되었다”와 같은 정량적인 결론을 내릴 수 있습니다."
  },
  {
    "objectID": "posts/cs/compiler/4-toolkit/index.html#공통-유틸리티-함수-util.py",
    "href": "posts/cs/compiler/4-toolkit/index.html#공통-유틸리티-함수-util.py",
    "title": "컴파일러 백엔드 시리즈 4부(부록): 컴파일러 툴킷",
    "section": "12. 공통 유틸리티 함수 (util.py)",
    "text": "12. 공통 유틸리티 함수 (util.py)\n파이프라인 전반에 걸쳐 사용된 몇 가지 편의 함수들이 util.py에 정의되어 있습니다.\n\n1. flatten(ll)\nreassemble 함수 등에서 여러 기본 블록(리스트의 리스트)을 다시 하나의 긴 명령어 리스트로 합칠 때 사용됩니다.\nimport itertools\n\ndef flatten(ll):\n    \"\"\"Flatten an iterable of iterable to a single list.\n    \"\"\"\n    return list(itertools.chain(*ll))\n\n\n2. fresh(seed, names)\ncfg.py의 block_map 함수에서 레이블이 없는 익명 블록(anonymous block)에 b1, b2와 같이 고유한 이름을 붙여줄 때 사용됩니다.\ndef fresh(seed, names):\n    \"\"\"Generate a new name that is not in `names` starting with `seed.\n    \"\"\"\n    i = 1\n    while True:\n        name = seed + str(i)\n        if name not in names:\n            return name\n        i += 1"
  },
  {
    "objectID": "posts/cs/compiler/2-ssa/index.html",
    "href": "posts/cs/compiler/2-ssa/index.html",
    "title": "컴파일러 백엔드 시리즈 2부: SSA 폼 변환과 지배자 트리",
    "section": "",
    "text": "1부에서는 Bril 코드를 기본 블록으로 나누어 제어 흐름 그래프(CFG)를 구축했습니다. CFG가 “어디로 갈 수 있는가”에 대한 흐름을 보여준다면, 2부에서는 “어떤 노드를 실행하기 위해 반드시 먼저 거쳐야 하는 노드가 무엇인가”에 대한 구조를 분석합니다.\n이것이 바로 지배자(Dominator) 분석이며, SSA 폼 변환의 심장부입니다."
  },
  {
    "objectID": "posts/cs/compiler/2-ssa/index.html#지배자-분석-반드시-거치는-길-찾기",
    "href": "posts/cs/compiler/2-ssa/index.html#지배자-분석-반드시-거치는-길-찾기",
    "title": "컴파일러 백엔드 시리즈 2부: SSA 폼 변환과 지배자 트리",
    "section": "4. 지배자 분석: “반드시 거치는 길” 찾기",
    "text": "4. 지배자 분석: “반드시 거치는 길” 찾기\n\n지배 (Dominance)란? CFG에서 노드 \\(A\\)가 노드 \\(B\\)를 지배(dominates)한다는 것은, 프로그램의 진입(entry) 노드에서 \\(B\\)로 가는 모든 경로가 반드시 \\(A\\)를 거쳐야 함을 의미합니다. (이때 \\(A\\)는 \\(B\\) 자신일 수도 있습니다.) * \\(LaTeX\\) 표기: \\(A \\text{ dom } B\\) * 직관적 의미: \\(B\\)를 실행했다면, 그전에 \\(A\\)는 무조건 실행되었음이 보장된다. * 예시: 루프(loop)의 헤더(header) 블록은 루프 본체(body)의 모든 블록을 지배합니다.\n\ndom.py 스크립트는 이 지배 관계를 계산하고, 이를 바탕으로 SSA 변환에 필수적인 두 가지 핵심 자료구조를 구축합니다.\n\n지배자 (Dominators) / get_dom: 각 노드 \\(n\\)에 대해, \\(n\\)을 지배하는 모든 노드의 집합 \\(Dom(n)\\)을 계산합니다.\n지배 경계 (Dominance Frontier) / dom_fronts: \\(\\phi\\) 함수를 어디에 삽입할지 알려주는 핵심 정보입니다.\n\n\n1. 지배자 관계 계산 (get_dom)\nget_dom 함수는 고전적인 반복적 데이터 흐름 분석(iterative data-flow analysis) 알고リズム을 사용하여 지배자 집합 \\(Dom(n)\\)을 계산합니다.\n이 알고리즘은 다음의 재귀적인 정의에 기반합니다. \\[Dom(n) = \\{n\\} \\cup \\left( \\bigcap_{p \\in \\text{pred}(n)} Dom(p) \\right)\\]\n\n\\(Dom(n)\\): 노드 \\(n\\)의 지배자 집합\n\\(\\text{pred}(n)\\): 노드 \\(n\\)의 모든 전임자(predecessor) 노드 집합\n(예외: 진입 노드 \\(n_0\\)의 경우 \\(Dom(n_0) = \\{n_0\\}\\) 입니다.)\n\n\n코드 해설\nget_dom 함수는 이 수식을 ’고정점(fixed-point)’에 도달할 때까지 반복 계산합니다.\ndef get_dom(succ, entry):\n    pred = map_inv(succ)\n    # 1. RPO(Reverse Postorder)로 노드 순회 순서 결정 (빠른 수렴을 위함)\n    nodes = list(reversed(postorder(succ, entry))) \n\n    # 2. 초기화: Dom(n) = {모든 노드} (데이터 흐름 분석의 'Top' 원소)\n    dom = {v: set(nodes) for v in succ}\n    # 진입 노드의 Dom(entry)는 {entry}여야 하지만,\n    # 아래 루프의 첫 번째 반복에서 자동으로 그렇게 설정됩니다.\n\n    while True:\n        changed = False\n\n        # 3. 모든 노드를 RPO 순서로 순회\n        for node in nodes:\n            # 4. Meet 연산: pred(node)의 Dom 집합들의 교집합(intersection) 계산\n            new_dom = intersect(dom[p] for p in pred[node])\n            # 5. Transfer 함수: {n}을 추가\n            new_dom.add(node)\n\n            # 6. 수렴(Convergence) 확인\n            if dom[node] != new_dom:\n                dom[node] = new_dom\n                changed = True\n\n        if not changed:\n            break  # 고정점에 도달하면(더 이상 변경이 없으면) 종료\n\n    return dom"
  },
  {
    "objectID": "posts/cs/compiler/2-ssa/index.html#지배자-트리-dominator-tree",
    "href": "posts/cs/compiler/2-ssa/index.html#지배자-트리-dominator-tree",
    "title": "컴파일러 백엔드 시리즈 2부: SSA 폼 변환과 지배자 트리",
    "section": "2. 지배자 트리 (Dominator Tree)",
    "text": "2. 지배자 트리 (Dominator Tree)\nget_dom이 계산한 \\(Dom(n)\\)은 모든 지배자 집합입니다. 하지만 이 관계는 ‘트리’ 구조로 단순화할 수 있습니다.\n\n즉시 지배자 (Immediate Dominator, idom)\n노드 \\(B\\)를 지배하는 노드 \\(A\\)가 \\(B\\)의 즉시 지배자라는 것은, \\(A\\)와 \\(B\\) 사이에 \\(A\\)를 지배하면서 \\(B\\)를 지배하는 다른 노드가 존재하지 않는다는 의미입니다. (즉, \\(A\\)가 \\(B\\)로 가는 길의 ‘마지막’ 지배자입니다.)\n\n진입 노드를 제외한 모든 노드는 유일한(unique) 즉시 지배자를 가집니다.\n\n이 idom 관계를 모아 그린 것이 지배자 트리(Dominator Tree)입니다. CFG가 복잡한 그래프일지라도, 지배자 트리는 항상 단순한 트리 구조가 됩니다. dom_tree 함수는 get_dom의 결과를 바탕으로 이 idom 관계(부모-자식 관계)를 계산합니다."
  },
  {
    "objectID": "posts/cs/compiler/2-ssa/index.html#지배-경계-dominance-frontier",
    "href": "posts/cs/compiler/2-ssa/index.html#지배-경계-dominance-frontier",
    "title": "컴파일러 백엔드 시리즈 2부: SSA 폼 변환과 지배자 트리",
    "section": "3. 지배 경계 (Dominance Frontier)",
    "text": "3. 지배 경계 (Dominance Frontier)\n드디어 SSA 변환의 가장 핵심적인 개념인 지배 경계(Dominance Frontier)입니다.\n\n지배 경계 (Dominance Frontier, DF) 란?\n노드 \\(A\\)의 지배 경계 \\(DF(A)\\)는, \\(A\\)가 지배하는 노드(\\(A\\) 자신 포함)의 후임자이면서, \\(A\\)가 엄격하게(strictly) 지배하지는 않는 노드들의 집합입니다.\n\n엄격한 지배(Strict Dominance): \\(A \\text{ dom } B\\) 이고 \\(A \\ne B\\) 인 경우.\n직관적 의미: 변수의 영향력이 \\(A\\)의 ’지배 영역’을 벗어나 처음으로 도달하는 합류 지점(join point)입니다.\n\n\n이것이 왜 중요할까요?\n어떤 블록 \\(A\\)에서 변수 \\(x\\)에 새로운 값이 할당(정의)되었다고 가정해봅시다. 이 \\(x\\)의 값은 \\(A\\)가 지배하는 모든 블록에서 유효합니다. 하지만 \\(A\\)의 ’지배 영역’을 벗어나는 순간(즉, \\(DF(A)\\)에 속하는 블록), 다른 경로에서 온 \\(x\\)의 값과 합쳐져야 합니다.\n따라서 \\(DF(A)\\)는 \\(\\phi\\) (phi) 함수가 삽입되어야 할 위치를 정확히 알려줍니다.\n\n코드 해설 (dom_fronts)\ndom_fronts 함수는 이 정의를 코드로 정확하게 구현합니다.\ndef dom_fronts(dom, succ):\n    \"\"\"Compute the dominance frontier, given the dominance relation.\n    \"\"\"\n    # dom_inv[A] = A가 지배하는 모든 노드 집합\n    dom_inv = map_inv(dom)\n\n    frontiers = {}\n    for block in dom:  # 모든 노드 A (block)에 대해\n        # Find all successors of dominated blocks.\n        dominated_succs = set()\n        # 1. A가 지배하는 모든 노드(dominated)를 찾고,\n        for dominated in dom_inv[block]:\n            # 2. 그 노드들의 모든 후임자(successors)를 찾는다.\n            dominated_succs.update(succ[dominated])\n\n        # 3. 이 후임자(b)들 중에서,\n        #    A가 '엄격하게' 지배하지 않는 노드만 필터링한다.\n        frontiers[block] = [b for b in dominated_succs\n                            if b not in dom_inv[block] or b == block]\n\n    return frontiers"
  },
  {
    "objectID": "posts/cs/compiler/2-ssa/index.html#ssa-폼-변환-phi-함수와-변수-이름-변경",
    "href": "posts/cs/compiler/2-ssa/index.html#ssa-폼-변환-phi-함수와-변수-이름-변경",
    "title": "컴파일러 백엔드 시리즈 2부: SSA 폼 변환과 지배자 트리",
    "section": "5. SSA 폼 변환: \\(\\phi\\) 함수와 변수 이름 변경",
    "text": "5. SSA 폼 변환: \\(\\phi\\) 함수와 변수 이름 변경\n이제 우리는 CFG, 지배자 트리, 그리고 지배 경계라는 재료를 모두 확보했습니다. 이 재료들을 사용해 IR을 SSA (Static Single Assignment) 폼으로 변환할 차례입니다.\n\nSSA (Static Single Assignment)란? 모든 변수(variable)가 프로그램 텍스트 상에서 단 한 번만 할당(assignment)되도록 보장하는 IR의 한 형태입니다. * 예시: x = 1; x = x + 1; * SSA 변환: x.0 = 1; x.1 = add x.0 1;\n\n이 “단일 할당” 속성 덕분에, 변수의 ‘정의(definition)’와 ’사용(use)’ 관계가 매우 명확해져, 다양한 최적화를 강력하고 효율적으로 만듭니다.\n이 변환은 두 단계 알고리즘으로 수행됩니다.\n\n\\(\\phi\\) 함수 삽입: 지배 경계(DF)를 이용해 \\(\\phi\\) 함수가 필요한 위치를 찾습니다.\n변수 이름 변경 (Renaming): 지배자 트리(Dominator Tree)를 순회하며 모든 변수의 정의와 사용을 x.0, x.1 등으로 다시 명명합니다.\n\n\n1단계: \\(\\phi\\) 함수 위치 선정 (get_phis)\nget_phis 함수는 dom_fronts가 계산한 지배 경계를 사용해 \\(\\phi\\) 함수가 필요한 위치를 찾습니다.\n\n\\(v\\)에 대한 정의가 블록 \\(D\\)에서 발생할 때, \\(DF(D)\\)에 속하는 모든 블록은 \\(v\\)에 대한 \\(\\phi\\) 함수가 필요할 수 있는 ’합류 지점’입니다.\nget_phis는 이 과정을 \\(\\phi\\) 함수 자신이 또 다른 정의가 되는 것까지 고려하여, 새로운 \\(\\phi\\) 함수가 더 이상 추가되지 않을 때까지 반복적으로(Iterated Dominance Frontier) 수행합니다.\n\ndef get_phis(blocks, df, defs):\n    \"\"\"Find where to insert phi-nodes in the blocks.\n    ...\n    \"\"\"\n    phis = {b: set() for b in blocks}\n    for v, v_defs in defs.items():\n        v_defs_list = list(v_defs)  # W = 리스트 (워크리스트)\n        for d in v_defs_list:  # W에서 하나씩 꺼내는 동안 (W가 증가 가능)\n            for block in df[d]:  # d의 지배 경계에 속하는 모든 블록\n                if v not in phis[block]:\n                    # 이 블록에 v에 대한 phi 함수가 필요하다고 표시\n                    phis[block].add(v)\n                    # phi 함수 자체가 새로운 정의이므로,\n                    # 이 블록(block)도 워크리스트에 추가\n                    if block not in v_defs_list:\n                        v_defs_list.append(block)\n    return phis\n\n\n2단계: 변수 이름 변경 (ssa_rename)\nssa_rename 함수는 지배자 트리를 전위 순회(pre-order traversal)하는 재귀 알고리즘을 사용해 실제 변수 이름을 v.0, v.1 등으로 변경합니다.\n\n각 변수명(예: ‘x’)마다, 현재 유효한 이름(예: ‘x.3’)을 저장하는 스택을 유지합니다.\n지배자 트리를 순회하는 이유: 트리를 따라 내려갈 때(즉, \\(A\\)에서 \\(A\\)가 지배하는 \\(B\\)로 이동할 때), 부모(\\(A\\))에서 정의된 변수 버전이 자식(\\(B\\))에서도 유효함이 보장됩니다.\n\n_rename(block) 함수의 핵심 로직은 다음과 같습니다.\n\n스택 백업: 현재 스택 상태를 old_stack에 저장합니다.\n\\(\\phi\\) 함수 정의: 현재 블록의 \\(\\phi\\) 함수 목적지(dest) 이름을 새로 만듭니다(예: x.4). 이 새 이름을 스택에 푸시합니다.\n일반 명령어 순회:\n\n사용(args): 명령어의 인자는 스택의 맨 위(stack[arg][0]) 이름으로 교체합니다.\n정의(dest): 명령어의 목적지(dest)는 새 이름을 만들고(예: v.1), 스택에 푸시합니다.\n\n후임자(\\(\\phi\\)) 인자 채우기: CFG의 후임자(successor) 블록에 있는 \\(\\phi\\) 함수의 인자를 현재 스택의 맨 위 이름으로 채워줍니다.\n재귀 호출: 지배자 트리의 자식(child)에 대해 _rename(b)를 재귀 호출합니다.\n스택 복원: old_stack을 사용해 스택을 재귀 호출 이전 상태로 되돌립니다. (형제 노드에게 영향을 주지 않기 위함)\n\ndef ssa_rename(blocks, phis, succ, domtree, args):\n    stack = defaultdict(list, {v: [v] for v in args}) # var -&gt; [v.2, v.1, v.0]\n    # ... (phi_args, phi_dests, counters 초기화) ...\n\n    def _push_fresh(var):\n        fresh = '{}.{}'.format(var, counters[var])\n        counters[var] += 1\n        stack[var].insert(0, fresh)\n        return fresh\n\n    def _rename(block):\n        # 1. 스택 상태 저장\n        old_stack = {k: list(v) for k, v in stack.items()}\n\n        # 2. 이 블록의 phi-node 목적지(dest) 이름 변경\n        for p in phis[block]:\n            phi_dests[block][p] = _push_fresh(p)\n\n        # 3. 일반 명령어 순회 (사용 -&gt; 정의 순)\n        for instr in blocks[block]:\n            if 'args' in instr:\n                instr['args'] = [stack[arg][0] for arg in instr['args']]\n            if 'dest' in instr:\n                instr['dest'] = _push_fresh(instr['dest'])\n\n        # 4. 후임자(successor) 블록의 phi-node 인자(arg) 채우기\n        for s in succ[block]:\n            for p in phis[s]:\n                if stack[p]:\n                    phi_args[s][p].append((block, stack[p][0]))\n                # ... (undefined 처리) ...\n\n        # 5. 지배자 트리의 자식 노드 재귀 방문\n        for b in sorted(domtree[block]):\n            _rename(b)\n\n        # 6. 이 블록에서 정의한 이름들을 스택에서 팝 (상태 복원)\n        stack.clear()\n        stack.update(old_stack)\n\n    entry = list(blocks.keys())[0]\n    _rename(entry)\n    # ... (결과 반환) ..."
  },
  {
    "objectID": "posts/cs/compiler/2-ssa/index.html#ssa-폼-검증하기-is_ssa",
    "href": "posts/cs/compiler/2-ssa/index.html#ssa-폼-검증하기-is_ssa",
    "title": "컴파일러 백엔드 시리즈 2부: SSA 폼 변환과 지배자 트리",
    "section": "6. SSA 폼 검증하기 (is_ssa)",
    "text": "6. SSA 폼 검증하기 (is_ssa)\nto_ssa.py의 변환은 매우 복잡합니다. 이 변환이 성공했는지, 그 결과물이 SSA의 핵심 속성을 만족하는지 어떻게 보장할 수 있을까요? is_ssa.py 스크립트는 이 변환을 검증하는 간단한 유틸리티입니다.\n\nSSA의 핵심 정의: 모든 변수는 함수 내의 텍스트에서 단 한 번만 할당(정의)되어야 합니다.\n\nis_ssa 함수는 assigned라는 집합(set)을 사용해, 함수 전체를 선형 스캔하며 ‘dest’ 키를 가진 변수명이 이미 assigned 집합에 있는지(즉, 중복 정의되었는지) 검사합니다.\ndef is_ssa(bril):\n    \"\"\"Check whether a Bril program is in SSA form.\n    \"\"\"\n    for func in bril['functions']:\n        assigned = set()\n        for instr in func['instrs']:\n            if 'dest' in instr:\n                if instr['dest'] in assigned:\n                    # This variable was already assigned to. Not SSA.\n                    return False\n                else:\n                    # This is the first assignment. Record it.\n                    assigned.add(instr['dest'])\n    # No variable was assigned to more than once.\n    return True"
  }
]